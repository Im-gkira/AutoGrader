{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "DCCNN - training.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_FZpcpTTFKj"
      },
      "source": [
        "# Notebook For Training Character Recognition\n",
        "\n",
        "### Datasets :\n",
        "#### 1. Digits (0-9) : MNIST (28 * 28)\n",
        "#### 2. Symbols ( ‘(’ , ‘)’, ‘-’, ‘+’, ‘*’ ): Kaggle Handwritten Mathematical Symbols Dataset (45 * 45)\n",
        "\n",
        "### Preprocessing of symbols to match MNIST digits :\n",
        "Converted to Binary \n",
        "\n",
        "Padded to 20 * 20 (preserving the aspect ratio)\n",
        "\n",
        "Padded to 28 * 28 using Centre of mass\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0q3K_p2gmws",
        "outputId": "a44ef08a-fb26-46ea-c3d0-497680767fa9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "ZtCuc2IFg8lK",
        "outputId": "f5613a83-0873-44bf-b600-74b6bb6e708b"
      },
      "source": [
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"drive/MyDrive/data.rar\", outdir=\"data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patool in /usr/local/lib/python3.7/dist-packages (1.12)\n",
            "patool: Extracting drive/MyDrive/data.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/drive/MyDrive/data.rar\n",
            "patool:     with cwd='data'\n",
            "patool: ... drive/MyDrive/data.rar extracted to `data'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAuN4uYKTFKm"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpzI4r6wTFKo"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm  \n",
        "import keras\n",
        "import math\n",
        "from scipy import ndimage"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE7lpfncTFKp"
      },
      "source": [
        "### Defining Image Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPTH5l5_TFKq"
      },
      "source": [
        "train_dir = \"data/extracted_images\"\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82L-Nx0UTFKr"
      },
      "source": [
        "### Data : Collecting images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOUjV310TFKr",
        "outputId": "0aacc87b-2fea-40d3-f09b-7fa8d32f893b"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "     \n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    data_format='channels_first',\n",
        "    validation_split=0.2) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(28, 28),\n",
        "    color_mode = \"grayscale\",\n",
        "    batch_size=20,\n",
        "    shuffle = True,\n",
        "    classes = ['0','1','2','3','4','5','6','7','8','9','+','-','times','(',')'],\n",
        "    class_mode=\"sparse\",\n",
        "    subset='training') \n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(28, 28),\n",
        "    color_mode = \"grayscale\",\n",
        "    batch_size=20,\n",
        "    shuffle = True,\n",
        "    classes = ['0','1','2','3','4','5','6','7','8','9','+','-','times','(',')'],\n",
        "    class_mode=\"sparse\",\n",
        "    subset='validation') "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 148219 images belonging to 15 classes.\n",
            "Found 37047 images belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_o_zoKtTFKs"
      },
      "source": [
        " # Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jAuPQfwTFKt"
      },
      "source": [
        "import keras\n",
        "keras.backend.set_image_data_format('channels_first')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23XwBdaBTFKu"
      },
      "source": [
        "## ------------------------------------------Deep Learning Model : DCCNN-------------------------------------------\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT7LgHknTFKv",
        "outputId": "d4842259-95d6-4d4c-d2a6-054a4fc5e4fc"
      },
      "source": [
        "from keras.layers import merge, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import MaxPooling2D, Convolution2D\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "nb_filters_1 = 64\n",
        "nb_filters_2 = 128\n",
        "nb_filters_3 = 256\n",
        "nb_conv = 3\n",
        "nb_conv_mid = 4\n",
        "nb_conv_init = 5\n",
        "\n",
        "init = Input(shape=(1, 28, 28),)\n",
        "\n",
        "fork11 = Convolution2D(nb_filters_1, nb_conv_init, nb_conv_init,  activation=\"relu\", padding='same')(init)\n",
        "fork12 = Convolution2D(nb_filters_1, nb_conv_init, nb_conv_init, activation=\"relu\", padding='same')(init)\n",
        "merge1 = concatenate([fork11, fork12], axis=1, name='merge1')\n",
        "# concat_feat = concatenate([concat_feat, x], mode='concat', axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
        "maxpool1 = MaxPooling2D(strides=(2,2), padding='same')(merge1)\n",
        "\n",
        "fork21 = Convolution2D(nb_filters_2, nb_conv_mid, nb_conv_mid, activation=\"relu\", padding='same')(maxpool1)\n",
        "fork22 = Convolution2D(nb_filters_2, nb_conv_mid, nb_conv_mid, activation=\"relu\", padding='same')(maxpool1)\n",
        "merge2 = concatenate([fork21, fork22, ], axis=1, name='merge2')\n",
        "maxpool2 = MaxPooling2D(strides=(2,2), padding='same')(merge2)\n",
        "\n",
        "fork31 = Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", padding='same')(maxpool2)\n",
        "fork32 = Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", padding='same')(maxpool2)\n",
        "fork33 = Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", padding='same')(maxpool2)\n",
        "fork34 = Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", padding='same')(maxpool2)\n",
        "fork35 = Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", padding='same')(maxpool2)\n",
        "fork36 = Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", padding='same')(maxpool2)\n",
        "merge3 = concatenate([fork31, fork32, fork33, fork34, fork35, fork36, ], axis=1, name='merge3')\n",
        "maxpool3 = MaxPooling2D(strides=(2,2), padding='same')(merge3)\n",
        "\n",
        "dropout = Dropout(0.5)(maxpool3)\n",
        "\n",
        "flatten = Flatten()(dropout)\n",
        "output = Dense(15, activation=\"softmax\")(flatten)\n",
        "\n",
        "model = Model(inputs=init, outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1, 28, 28)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 6, 6)     1664        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 6, 6)     1664        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " merge1 (Concatenate)           (None, 128, 6, 6)    0           ['conv2d[0][0]',                 \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 3, 3)    0           ['merge1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 1, 1)    262272      ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 1, 1)    262272      ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " merge2 (Concatenate)           (None, 256, 1, 1)    0           ['conv2d_2[0][0]',               \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 256, 1, 1)   0           ['merge2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 256, 1, 1)    590080      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 256, 1, 1)    590080      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 256, 1, 1)    590080      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 256, 1, 1)    590080      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 256, 1, 1)    590080      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 256, 1, 1)    590080      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " merge3 (Concatenate)           (None, 1536, 1, 1)   0           ['conv2d_4[0][0]',               \n",
            "                                                                  'conv2d_5[0][0]',               \n",
            "                                                                  'conv2d_6[0][0]',               \n",
            "                                                                  'conv2d_7[0][0]',               \n",
            "                                                                  'conv2d_8[0][0]',               \n",
            "                                                                  'conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 1536, 1, 1)  0           ['merge3[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1536, 1, 1)   0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1536)         0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 15)           23055       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,091,407\n",
            "Trainable params: 4,091,407\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf0tADoeTFKw",
        "outputId": "5d7f4ec7-9491-46c7-d038-29e719edfad1"
      },
      "source": [
        "from keras import optimizers\n",
        "ada = tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)\n",
        "model.compile(optimizer=ada,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              validation_steps=100,\n",
        "                              epochs=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 34s 33ms/step - loss: 2.4000 - accuracy: 0.1795 - val_loss: 2.2606 - val_accuracy: 0.1945\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 2.0344 - accuracy: 0.3200 - val_loss: 1.7617 - val_accuracy: 0.3975\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 1.6954 - accuracy: 0.4405 - val_loss: 1.3765 - val_accuracy: 0.5410\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 1.4011 - accuracy: 0.5260 - val_loss: 1.2828 - val_accuracy: 0.5890\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 1.1822 - accuracy: 0.6050 - val_loss: 1.0822 - val_accuracy: 0.6920\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 1.0249 - accuracy: 0.6625 - val_loss: 1.0817 - val_accuracy: 0.6345\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.8704 - accuracy: 0.7175 - val_loss: 0.8148 - val_accuracy: 0.7410\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.8260 - accuracy: 0.7255 - val_loss: 0.9142 - val_accuracy: 0.7170\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.8099 - accuracy: 0.7435 - val_loss: 0.6583 - val_accuracy: 0.7965\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.7339 - accuracy: 0.7690 - val_loss: 0.6068 - val_accuracy: 0.8195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBaNQQzYTFKw"
      },
      "source": [
        "## Validation Accuracy [10th Epoch] : ~97%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pukthyCeTFKx"
      },
      "source": [
        "model.save('contents/DCNN_10AD_sy.h5')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJ3JK0KTFKx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}